{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "48a476f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for Missing Token for Sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each model\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "    \n",
    "    # Explicit calculation of TP, TN, FP, FN\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "17914552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for Missing Token for Sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each model\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "    \n",
    "    # Explicit calculation of TP, TN, FP, FN\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "f802cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for runtime for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "fe147be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for equi for Sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "02cfd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for equi for Sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "# Unique SQL statements in each DataFrame\n",
    "#stats_sql_statements = set(stats['SQL_Statement'].unique())\n",
    "#missing_word_sql_statements = set(missing_word['SQL_Statement'].unique())\n",
    "# SQL statements present in stats but not in missing_word\n",
    "#only_in_stats = stats_sql_statements - missing_word_sql_statements\n",
    "\n",
    "# SQL statements present in missing_word but not in stats\n",
    "#only_in_missing_word = missing_word_sql_statements - stats_sql_statements\n",
    "\n",
    "#print(f\"SQL Statements only in stats: {len(only_in_stats)}\")\n",
    "#print(f\"SQL Statements only in missing_word: {len(only_in_missing_word)}\")\n",
    "#print(\"SQL Statements only in stats:\")\n",
    "#print(only_in_stats)\n",
    "\n",
    "#print(\"\\nSQL Statements only in missing_word:\")\n",
    "#print(only_in_missing_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3510bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for syntax error for Sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffb3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Nestedness level for syntax error for Sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Nestedness_Level'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Nestedness_Level'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Nestedness_Level']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Nestedness_Level']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='BuGn', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Nestedness Level', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Nestedness_level_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5947f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Function count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "fcd944a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for Missing Token for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_join'] = merged_df['Syntax_Error_join'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_join']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_missing_token_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "7967bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for Missing Token for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "59b80f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for Missing Token for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "84d020a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for Runtime for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2186f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "25762318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "59459deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_equi_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f744cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d417f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45cdb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Function for equi for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Function_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Function_Count'].median()\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Function_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Function_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Purples', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Function Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Function_count_plot_syn_error_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "39c4a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for runtime word count\n",
    "#works perfectly well number of TP,TN,FP,FN and plot in the x axis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    categories = [f'{llm}_tp', f'{llm}_tn', f'{llm}_fp', f'{llm}_fn']\n",
    "    custom_labels = []\n",
    "    plot_data = []\n",
    "\n",
    "    for cat in categories:\n",
    "        # Calculate average and total correctly\n",
    "        true_indices = merged_df[cat] == True\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        #label = f\"{cat.split('_')[-1].upper()} ({avg:.2f}/{count})\"\n",
    "        custom_labels.append(label)\n",
    "        merged_df['category'] = cat\n",
    "        plot_data.append(merged_df[true_indices].copy())\n",
    "\n",
    "    plot_data = pd.concat(plot_data)\n",
    "\n",
    "    if not plot_data.empty:\n",
    "        sns.boxplot(x='category', y='Word_Count', data=plot_data, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "        sns.stripplot(x='category', y='Word_Count', data=plot_data, color='orange', size=5, jitter=True, ax=ax)\n",
    "        #sns.histplot(x='category', y='Function_Count', data=plot_data)\n",
    "        \n",
    "        ax.set_xticklabels(custom_labels, rotation=0, ha='center', fontsize=26)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "        ax.set_ylabel('Word Count',fontsize=22)\n",
    "        ax.set_xlabel('')\n",
    "        #plt.show()\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Unique SQL statements in each DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "d6985caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with join for word count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_join'] = merged_df['Syntax_Error_join'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_join']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_missing_token_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "1eca0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with sdss for word count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "de58e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with sqlshare for word count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Word Count (log scale)', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "671e9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count equi with sdss as it has no value for FN in gpt4\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "d6fb0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count equi with sqlshare as it has no value for FN in gpt4\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_dat\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Word Count', fontsize=16)\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Word Count (log scale)', fontsize=22)\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "c528990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count equi with join \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "    \n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_equi_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8cb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count syntax error with sdss \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "    \n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310746b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count syntax error with sqlshare \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Word Count (log scale)', fontsize=22)\n",
    "    \n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe741e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count syntax error with join \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Word_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Word_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Word_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Word_Count', data=plot_data, order=categories, color='orange', size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Word Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "    \n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_word_count_plot_syn_error_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicate count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "3e524627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with join for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_join'] = merged_df['Syntax_Error_join'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_join']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_missing_token_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "111fef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with sdss for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Predicate Count', fontsize=16)\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Predicate Count (log scale)', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "73999f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Predicate for Missing Token for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Predicate_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Predicate_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Greens', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "c01f56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime with sdss for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "9f058d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equi with sdss for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Predicate Count (log scale)', fontsize=22)\n",
    "    #ax.set_ylabel('Predicate Count', fontsize=16)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "fcfee9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equi with join for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_equi_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "5f903fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for predicate for equi for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Predicate_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Predicate_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Greens', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2584d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntax error with sdss for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Predicate Count (log scale)', fontsize=22)\n",
    "    #ax.set_ylabel('Predicate Count', fontsize=16)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25cf856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for predicate for syntax error for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Predicate_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Predicate_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Greens', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156263c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntax error with join for predicate count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Predicate_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Predicate_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Predicate_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Predicate_Count', data=plot_data, order=categories, color=(35/255, 155/255, 56/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Predicate Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Predicate_count_plot_syn_error_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "d07cfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with join for Table count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_join'] = merged_df['Syntax_Error_join'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Syntax_Error_join']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Table_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Table_Count', data=plot_data, order=categories, color=(170/255, 43/255, 55/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_missing_token_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7acc7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for Missing Token for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "00013d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for Missing Token for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "35fb807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for runtime for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "0f4edff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for equi for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ca3ca162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for equi for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "5a6c9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equi with join for Table count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Table_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Table_Count', data=plot_data, order=categories, color=(170/255, 43/255, 55/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_equi_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc2d45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for syntax error for sdss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef620c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Table count for syntax error for sqlshare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Table_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Table_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Reds', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31fe5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntax error with join for Table count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Table_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Table_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Table_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Table_Count', data=plot_data, order=categories, color=(170/255, 43/255, 55/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_ylabel('Table Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Table_count_plot_syn_error_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "Column Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "888962c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equi with sdss for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  \n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_equi_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "3dbe43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equi with sqlshare for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Column Count', fontsize=16)\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Column Count (log scale)', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_equi_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8a08373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Column count for equi for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Equivalence\\equi_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Column_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Column_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_equi_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ff4a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntax error with sdss for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  \n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_syn_error_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e40532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntax error with sqlshare for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Column Count', fontsize=16)\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Column Count (log scale)', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_syn_error_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac55b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Column count for syntax error for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments  for Syntax Error\\syntax_error_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Column_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Column_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_syn_error_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "bbe8bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime with sdss for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Runtime\\sdss_runtime.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Original'] = merged_df['Original'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[llm] = merged_df[llm].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Plotting loop\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    y_true = merged_df['Original']\n",
    "    y_pred = merged_df[llm]\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  \n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_runtime_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "3464a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with sdss for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sdss_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sdss.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sdss'] = merged_df['Syntax_Error_sdss'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sdss']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    ax.set_yscale('log')  \n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_missing_token_sdss.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6c6a8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing token with sqlshare for column count as it has no value for FN in gpt4 and mistralai\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\sqlshare_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_sqlshare.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_sqlshare'] = merged_df['Syntax_Error_sqlshare'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_sqlshare']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    # Initialize data structure for categories\n",
    "    plot_data = pd.DataFrame()\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    custom_labels = []\n",
    "\n",
    "    # Loop through each category to collect data and labels\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        count = true_indices.sum()\n",
    "        label_part = cat.split('_')[-1].upper()\n",
    "        label = f\"{label_part}\\n {avg:.2f}\\n {med:.2f}\\n {count}\"\n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "\n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Ensure all categories are represented, even if empty\n",
    "    plot_data['category'] = pd.Categorical(plot_data['category'], categories=categories, ordered=True)\n",
    "\n",
    "    # Plot boxplot and stripplot\n",
    "    sns.boxplot(x='category', y='Column_Count', data=plot_data, order=categories, palette=sns.color_palette(\"colorblind\"), width=0.3, ax=ax, boxprops=dict(facecolor='none'))\n",
    "    sns.stripplot(x='category', y='Column_Count', data=plot_data, order=categories, color=(1/255, 115/255, 178/255), size=5, jitter=True, ax=ax)\n",
    "\n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(range(len(custom_labels)))\n",
    "    ax.set_xticklabels(custom_labels, rotation=0, ha='center',fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)  # Set y-axis labels font size\n",
    "    #ax.set_ylabel('Column Count', fontsize=16)\n",
    "    ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "    ax.set_ylabel('Column Count (log scale)', fontsize=22)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Save plots as PDF\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_missing_token_sqlshare.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "8951c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap for Column count for Missing Token for join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the directory for saving plots\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Load data\n",
    "stats = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Stats\\join_stats.csv\")\n",
    "missing_word = pd.read_csv(r\"C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\Results of LLM\\Experiments for Missing Token\\missing_token_join.csv\")\n",
    "\n",
    "# Data merging\n",
    "merged_df = pd.merge(stats, missing_word, on='SQL_Statement', how='inner')\n",
    "\n",
    "# Convert 'YES'/'NO' to 1/0\n",
    "merged_df['Syntax_Error_join'] = merged_df['Syntax_Error_join'].map({'YES': 1, 'NO': 0})\n",
    "for llm in ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']:\n",
    "    merged_df[f'Syntax_Error_{llm}'] = merged_df[f'Syntax_Error_{llm}'].map({'YES': 1, 'NO': 0}).fillna(1)\n",
    "\n",
    "# Define the list of models\n",
    "llms = ['gpt4', 'gpt3.5', 'llama3', 'mistralai', 'gemini']\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "for llm in llms:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_true = merged_df['Syntax_Error_join']\n",
    "    y_pred = merged_df[f'Syntax_Error_{llm}']\n",
    "\n",
    "    # Define categories\n",
    "    categories = ['TP', 'TN', 'FP', 'FN']\n",
    "    merged_df[f'{llm}_tp'] = (y_true == 1) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_tn'] = (y_true == 0) & (y_pred == 0)\n",
    "    merged_df[f'{llm}_fp'] = (y_true == 0) & (y_pred == 1)\n",
    "    merged_df[f'{llm}_fn'] = (y_true == 1) & (y_pred == 0)\n",
    "\n",
    "    plot_data = pd.DataFrame()  # Initialize DataFrame to store plot data\n",
    "    custom_labels = []  # Initialize list for custom labels\n",
    "\n",
    "    for cat in categories:\n",
    "        cat_name = f\"{llm}_{cat.lower()}\"\n",
    "        true_indices = merged_df[cat_name]\n",
    "        avg = merged_df.loc[true_indices, 'Column_Count'].mean() if true_indices.any() else 0\n",
    "        count = true_indices.sum()\n",
    "        med = merged_df.loc[true_indices, 'Column_Count'].median()\n",
    "        #label = f\"{cat}\\nAvg: {avg:.2f}\\nMed: {med:.2f}\\nTotal: {count}\" if count > 0 else cat\n",
    "        label = f\"{cat}\\n {avg:.2f}\\n {med:.2f}\\n {count}\" if count > 0 else cat\n",
    "        \n",
    "        # Append data to plot_data\n",
    "        merged_df.loc[true_indices, 'category'] = cat\n",
    "        plot_data = pd.concat([plot_data, merged_df[true_indices]])\n",
    "        \n",
    "        # Append label\n",
    "        custom_labels.append(label)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    unique_levels = pd.unique(merged_df['Column_Count']).astype(int)\n",
    "    heatmap_data = pd.DataFrame(index=sorted(unique_levels, reverse=True), columns=categories)\n",
    "    for category in categories:\n",
    "        category_data = plot_data.loc[plot_data['category'] == category, 'Column_Count']\n",
    "        count_data = category_data.value_counts().sort_index()\n",
    "        heatmap_data[category] = count_data.reindex(heatmap_data.index).fillna(0)\n",
    "\n",
    "    heatmap = sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt=\".0f\", annot_kws={\"size\": 26})\n",
    "    ax.set_xticklabels(custom_labels, fontsize=26)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=22)\n",
    "    ax.set_ylabel('Column Count', fontsize=22)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    for _, spine in heatmap.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pdf_filename = os.path.join(output_directory, f\"{llm}_Column_count_plot_missing_token_join.pdf\")\n",
    "    plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d77b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sdss Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [4/66, 1/42, 0, 1/21, 0, 0],  # GPT-4: Specific counts as provided\n",
    "    [10/66, 1/42, 1/46, 2/21, 3/19, 1/23],  # GPT-3.5: Random data for demonstration\n",
    "    [10/66,0,1/46,1/21,1/19,0],  # LLaMA-3: Random data for demonstration\n",
    "    [19/66,0,1/46,3/21,3/19,4/23],  # Mistral AI: Random data for demonstration\n",
    "    [23/66,6/42,6/46,3/21,5/19,8/23]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['Keyword', 'Column', 'Table', 'Value', 'Alias', 'Comparison']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "\n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Ratio',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 0.6, 0.1))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "ax.legend(loc='upper left', fontsize=20)\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"missing_token_type_sdss.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "# Display the bar chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c19ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sqlshare Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [2/54, 0, 2/28, 1/25, 1/20, 1/19],  # GPT-4: Specific counts as provided\n",
    "    [5/54,1/43,4/28,2/25,3/20,3/19],  # GPT-3.5: Random data for demonstration\n",
    "    [4/54,2/43,4/28,1/25,4/20,1/19],  # LLaMA-3: Random data for demonstration\n",
    "    [12/54,2/43,2/28,1/25,5/20,3/19],  # Mistral AI: Random data for demonstration\n",
    "    [26/54,8/43,6/28,4/25,10/20,7/19]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['Keyword', 'Column', 'Table', 'Value', 'Alias', 'Comparison']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "\n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Ratio',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 0.6, 0.1))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"missing_token_type_sqlshare.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "# Display the bar chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4e1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for join Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [2/38, 1/20, 0, 0, 0, 0],  # GPT-4: Specific counts as provided\n",
    "    [5/38,0,0,0,1/11,0],  # GPT-3.5: Random data for demonstration\n",
    "    [3/38,1/20,2/17,0,0,0],  # LLaMA-3: Random data for demonstration\n",
    "    [2/38,1/20,2/17,0,1/11,0],  # Mistral AI: Random data for demonstration\n",
    "    [15/38,5/20,2/17,4/10,2/11,6/13]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['Keyword', 'Column', 'Table', 'Value', 'Alias', 'Comparison']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "    \n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Ratio',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 0.6, 0.1))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"missing_token_type_join.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "#fig.savefig('missing_token_type_join.pdf', format='pdf')\n",
    "# Display the bar chart\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e09ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sdss Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [1, 0, 1, 4, 1, 1],  # GPT-4: Specific counts as provided\n",
    "    [1, 1, 7, 10, 3, 0],  # GPT-3.5: Random data for demonstration\n",
    "    [11,1,12,10,8,3],  # LLaMA-3: Random data for demonstration\n",
    "    [1,0,5,9,2,0],  # Mistral AI: Random data for demonstration\n",
    "    [10,3,18,17,4,3]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['aggr-attr', 'aggr-having', 'nested - mismatch', 'condition - mismatch', 'alias-undefined', 'alias-ambiguous']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "\n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Count',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 20, 2))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "ax.legend(loc='upper left', fontsize=20)\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"syntax_error_sdss.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "# Display the bar chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06dba391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sqlshare Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [2, 0, 0, 2, 2, 7],  # GPT-4: Specific counts as provided\n",
    "    [2,3,2,8,3,6],  # GPT-3.5: Random data for demonstration\n",
    "    [1,7,6,7,2,10],  # LLaMA-3: Random data for demonstration\n",
    "    [5,0,1,2,1,4],  # Mistral AI: Random data for demonstration\n",
    "    [9,10,15,12,19,16]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['aggr-attr', 'aggr-having', 'nested - mismatch', 'condition - mismatch', 'alias-undefined', 'alias-ambiguous']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "    \n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Count',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 21, 2))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"syntaz_error_sqlshare.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "#fig.savefig('missing_token_type_join.pdf', format='pdf')\n",
    "# Display the bar chart\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1c6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for join Type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Set specific data for GPT-4 and random data for other models\n",
    "# Data format: models x categories\n",
    "data = np.array([\n",
    "    [0, 3, 2, 3, 2, 0],  # GPT-4: Specific counts as provided\n",
    "    [4, 2, 11, 4, 0, 0],  # GPT-3.5: Random data for demonstration\n",
    "    [4,6,17,7,2,1],  # LLaMA-3: Random data for demonstration\n",
    "    [0,3,3,1,0,0],  # Mistral AI: Random data for demonstration\n",
    "    [5,8,18,6,4,2]   # Gemini: Random data for demonstration\n",
    "])\n",
    "\n",
    "categories = ['aggr-attr', 'aggr-having', 'nested - mismatch', 'condition - mismatch', 'alias-undefined', 'alias-ambiguous']\n",
    "models = ['GPT4', 'GPT3.5', 'LLama3', 'MistralAI', 'Gemini']\n",
    "\n",
    "# Colors that are colorblind friendly\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#ffff33']  # Unique color for each category\n",
    "\n",
    "# Setting up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bar_width = 0.15  # Width of the bars\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create bars for each category\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(index + i * bar_width, data[:, i], bar_width, label=category, color=colors[i])\n",
    "    \n",
    "for i in range(1, len(models)):\n",
    "    ax.axvline(x=i - bar_width, color='gray', linestyle='--')\n",
    "\n",
    "# Labeling and aesthetics\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Count',fontsize=24)\n",
    "ax.set_xticks(index + bar_width * (len(categories) - 1) / 2)\n",
    "ax.set_xticklabels(models, fontsize=24)\n",
    "ax.set_yticks(np.arange(0, 20, 2))\n",
    "\n",
    "#ax.set_yticks(range(0, 0.5)) \n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "#ax.legend()\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"syntaz_error_join.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n",
    "#fig.savefig('missing_token_type_join.pdf', format='pdf')\n",
    "# Display the bar chart\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a5260259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "output_directory = r'C:\\Users\\anany\\OneDrive\\Desktop\\MS_Thesis\\plots'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "# Data\n",
    "data = {\n",
    "    \"Runtime\": [\"GPT4\", \"GPT3.5\", \"Llama3\", \"Mistral AI\", \"Gemini\"],\n",
    "    \"FN\": [3, 6, 4, 4, 11],\n",
    "    \"FP\": [5, 8, 12, 41, 12]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = df.set_index(\"Runtime\").plot(kind='bar', color=[\"#377eb8\", \"#4daf4a\"], rot=0)\n",
    "plt.xlabel('')\n",
    "ax.set_ylabel('Counts', fontsize=20)  # Setting fontsize for y-axis label\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set fontsize for x-ticks and y-ticks\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "pdf_filename = os.path.join(output_directory, f\"FN_FP_runtime.pdf\")\n",
    "plt.savefig(pdf_filename, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc622e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
